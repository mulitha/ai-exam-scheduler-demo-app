{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dedb233-4ec1-4ec0-92c9-bdb6f36b5eb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__randomstate_ctor() takes from 0 to 1 positional arguments but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load trained model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model = joblib.load(\u001b[33m'\u001b[39m\u001b[33mGradientBoostingRegressor_model.pkl\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Map difficulty level to numerical values (if your model was trained with encoded values)\u001b[39;00m\n\u001b[32m      8\u001b[39m difficulty_map = {\u001b[33m'\u001b[39m\u001b[33mlow\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmedium\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhigh\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2\u001b[39m}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\anaconda3\\envs\\streamli\\Lib\\site-packages\\joblib\\numpy_pickle.py:749\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    744\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[32m    746\u001b[39m             \u001b[38;5;66;03m# A memory-mapped array has to be mapped with the endianness\u001b[39;00m\n\u001b[32m    747\u001b[39m             \u001b[38;5;66;03m# it has been written with. Other arrays are coerced to the\u001b[39;00m\n\u001b[32m    748\u001b[39m             \u001b[38;5;66;03m# native endianness of the host system.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m             obj = _unpickle(\n\u001b[32m    750\u001b[39m                 fobj,\n\u001b[32m    751\u001b[39m                 ensure_native_byte_order=ensure_native_byte_order,\n\u001b[32m    752\u001b[39m                 filename=filename,\n\u001b[32m    753\u001b[39m                 mmap_mode=validated_mmap_mode,\n\u001b[32m    754\u001b[39m             )\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\anaconda3\\envs\\streamli\\Lib\\site-packages\\joblib\\numpy_pickle.py:626\u001b[39m, in \u001b[36m_unpickle\u001b[39m\u001b[34m(fobj, ensure_native_byte_order, filename, mmap_mode)\u001b[39m\n\u001b[32m    624\u001b[39m obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     obj = unpickler.load()\n\u001b[32m    627\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m unpickler.compat_mode:\n\u001b[32m    628\u001b[39m         warnings.warn(\n\u001b[32m    629\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe file \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has been generated with a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    630\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mjoblib version less than 0.10. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    633\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    634\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\anaconda3\\envs\\streamli\\Lib\\pickle.py:1213\u001b[39m, in \u001b[36m_Unpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1211\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[32m   1212\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[32m-> \u001b[39m\u001b[32m1213\u001b[39m         dispatch[key[\u001b[32m0\u001b[39m]](\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1214\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[32m   1215\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\anaconda3\\envs\\streamli\\Lib\\site-packages\\joblib\\numpy_pickle.py:462\u001b[39m, in \u001b[36mNumpyUnpickler.load_build\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    460\u001b[39m     _array_payload = array_wrapper.read(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     _array_payload = array_wrapper.read(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m.ensure_native_byte_order)\n\u001b[32m    464\u001b[39m \u001b[38;5;28mself\u001b[39m.stack.append(_array_payload)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\anaconda3\\envs\\streamli\\Lib\\site-packages\\joblib\\numpy_pickle.py:284\u001b[39m, in \u001b[36mNumpyArrayWrapper.read\u001b[39m\u001b[34m(self, unpickler, ensure_native_byte_order)\u001b[39m\n\u001b[32m    282\u001b[39m     array = \u001b[38;5;28mself\u001b[39m.read_mmap(unpickler)\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     array = \u001b[38;5;28mself\u001b[39m.read_array(unpickler, ensure_native_byte_order)\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# Manage array subclass case\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array, \u001b[33m\"\u001b[39m\u001b[33m__array_prepare__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.subclass \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m    288\u001b[39m     unpickler.np.ndarray,\n\u001b[32m    289\u001b[39m     unpickler.np.memmap,\n\u001b[32m    290\u001b[39m ):\n\u001b[32m    291\u001b[39m     \u001b[38;5;66;03m# We need to reconstruct another subclass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\anaconda3\\envs\\streamli\\Lib\\site-packages\\joblib\\numpy_pickle.py:175\u001b[39m, in \u001b[36mNumpyArrayWrapper.read_array\u001b[39m\u001b[34m(self, unpickler, ensure_native_byte_order)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;66;03m# Now read the actual data.\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dtype.hasobject:\n\u001b[32m    174\u001b[39m     \u001b[38;5;66;03m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     array = pickle.load(unpickler.file_handle)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    177\u001b[39m     numpy_array_alignment_bytes = \u001b[38;5;28mself\u001b[39m.safe_get_numpy_array_alignment_bytes()\n",
      "\u001b[31mTypeError\u001b[39m: __randomstate_ctor() takes from 0 to 1 positional arguments but 2 were given"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load trained model\n",
    "model = joblib.load('GradientBoostingRegressor_model.pkl')\n",
    "\n",
    "# Map difficulty level to numerical values (if your model was trained with encoded values)\n",
    "difficulty_map = {'low': 0, 'medium': 1, 'high': 2}\n",
    "\n",
    "# Get user inputs\n",
    "difficulty_input = input(\"Enter difficulty level (low, medium, high): \").strip().lower()\n",
    "timeslot_id = int(input(\"Enter timeslot_id (e.g., 1): \").strip())\n",
    "classroom_id = int(input(\"Enter classroom_id (e.g., 10): \").strip())\n",
    "course_id = int(input(\"Enter course_id (e.g., 101): \").strip())\n",
    "\n",
    "# Validate and encode difficulty\n",
    "if difficulty_input not in difficulty_map:\n",
    "    raise ValueError(\"Invalid difficulty level. Choose from: low, medium, high.\")\n",
    "difficulty_encoded = difficulty_map[difficulty_input]\n",
    "\n",
    "# Create input DataFrame\n",
    "input_df = pd.DataFrame([{\n",
    "    'difficulty_level': difficulty_encoded,\n",
    "    'timeslot_id': timeslot_id,\n",
    "    'classroom_id': classroom_id,\n",
    "    'course_id': course_id\n",
    "}])\n",
    "\n",
    "# Predict\n",
    "predicted_days = model.predict(input_df)[0]\n",
    "print(f\"\\n Predicted Study Date Count: {predicted_days:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e7d74-61a8-474f-87e0-4c6aa5d51574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
